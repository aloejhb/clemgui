{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = 'processed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "em_downsampled_transformed_name = 'dp1_em_downsampled_stack_transformed'\n",
    "em_affine3d_file = os.path.join(processed_data_dir, f'transformed_stacks/{em_downsampled_transformed_name}_affine3d_mat.txt')\n",
    "\n",
    "landmark_dir = 'landmarks'\n",
    "landmark_base_name = 'landmarks_202404020045'\n",
    "landmark_file = os.path.join(landmark_dir, f'{landmark_base_name}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landmark_name</th>\n",
       "      <th>tag</th>\n",
       "      <th>x_EM</th>\n",
       "      <th>y_EM</th>\n",
       "      <th>z_EM</th>\n",
       "      <th>x_LM</th>\n",
       "      <th>y_LM</th>\n",
       "      <th>z_LM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pt-2</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>1392.065162</td>\n",
       "      <td>939.549477</td>\n",
       "      <td>89.762090</td>\n",
       "      <td>1368.949598</td>\n",
       "      <td>938.602359</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pt-3</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>1698.571514</td>\n",
       "      <td>874.969650</td>\n",
       "      <td>85.243414</td>\n",
       "      <td>1643.211884</td>\n",
       "      <td>868.415943</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pt-4</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>1410.085755</td>\n",
       "      <td>925.032202</td>\n",
       "      <td>470.814911</td>\n",
       "      <td>1407.837509</td>\n",
       "      <td>920.639177</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pt-5</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>1414.312151</td>\n",
       "      <td>731.356375</td>\n",
       "      <td>309.191181</td>\n",
       "      <td>1415.024726</td>\n",
       "      <td>727.486650</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pt-6</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>1470.753244</td>\n",
       "      <td>621.977165</td>\n",
       "      <td>313.577356</td>\n",
       "      <td>1481.816907</td>\n",
       "      <td>622.103430</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>landmark-1646</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>502.950788</td>\n",
       "      <td>861.809945</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>491.789428</td>\n",
       "      <td>851.392675</td>\n",
       "      <td>701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>landmark-1647</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>805.435878</td>\n",
       "      <td>515.025374</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>804.305056</td>\n",
       "      <td>515.025374</td>\n",
       "      <td>701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>landmark-1648</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>1018.603208</td>\n",
       "      <td>662.355362</td>\n",
       "      <td>695.000000</td>\n",
       "      <td>1026.788205</td>\n",
       "      <td>654.170365</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>landmark-1649</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>1624.355391</td>\n",
       "      <td>859.196862</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>1657.378081</td>\n",
       "      <td>873.873613</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>landmark-1650</td>\n",
       "      <td>confirmed</td>\n",
       "      <td>1246.336020</td>\n",
       "      <td>735.263683</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>1263.226202</td>\n",
       "      <td>725.944962</td>\n",
       "      <td>601.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     landmark_name        tag         x_EM        y_EM        z_EM  \\\n",
       "0             Pt-2  confirmed  1392.065162  939.549477   89.762090   \n",
       "1             Pt-3  confirmed  1698.571514  874.969650   85.243414   \n",
       "2             Pt-4  confirmed  1410.085755  925.032202  470.814911   \n",
       "3             Pt-5  confirmed  1414.312151  731.356375  309.191181   \n",
       "4             Pt-6  confirmed  1470.753244  621.977165  313.577356   \n",
       "..             ...        ...          ...         ...         ...   \n",
       "752  landmark-1646  confirmed   502.950788  861.809945  701.000000   \n",
       "753  landmark-1647  confirmed   805.435878  515.025374  701.000000   \n",
       "754  landmark-1648  confirmed  1018.603208  662.355362  695.000000   \n",
       "755  landmark-1649  confirmed  1624.355391  859.196862  699.000000   \n",
       "756  landmark-1650  confirmed  1246.336020  735.263683  576.000000   \n",
       "\n",
       "            x_LM        y_LM   z_LM  \n",
       "0    1368.949598  938.602359  100.0  \n",
       "1    1643.211884  868.415943  100.0  \n",
       "2    1407.837509  920.639177  500.0  \n",
       "3    1415.024726  727.486650  300.0  \n",
       "4    1481.816907  622.103430  300.0  \n",
       "..           ...         ...    ...  \n",
       "752   491.789428  851.392675  701.0  \n",
       "753   804.305056  515.025374  701.0  \n",
       "754  1026.788205  654.170365  699.0  \n",
       "755  1657.378081  873.873613  699.0  \n",
       "756  1263.226202  725.944962  601.0  \n",
       "\n",
       "[757 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "landmarkdf = pd.read_csv(landmark_file)\n",
    "# Rename x_EM, y_EM, z_EM to x_em_clemui, y_em_clemui, z_em_clemui\n",
    "# and x_LM, y_LM, z_LM to x_lm_clemui, y_lm_clemui, z_lm_clemui\n",
    "landmarkdf.rename(columns={\n",
    "    'x_EM': 'x_em_clemui',\n",
    "    'y_EM': 'y_em_clemui',\n",
    "    'z_EM': 'z_em_clemui',\n",
    "    'x_LM': 'x_lm_clemui',\n",
    "    'y_LM': 'y_lm_clemui',\n",
    "    'z_LM': 'z_lm_clemui'\n",
    "}, inplace=True)\n",
    "landmarkdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if landmark_name in landmarkdf is unique\n",
    "landmarkdf['landmark_name'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert EM to {em_transformed_name}\n",
    "landmarkdf[f'x_{em_downsampled_transformed_name}'] = landmarkdf['x_em_clemui']\n",
    "landmarkdf[f'y_{em_downsampled_transformed_name}'] = landmarkdf['y_em_clemui']\n",
    "landmarkdf[f'z_{em_downsampled_transformed_name}'] = landmarkdf['z_em_clemui']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert LM to {lm_name}\n",
    "lm_name = 'dp1_lm_anatomy_trial11_CLAHE'\n",
    "lm_scale_zyx = (100, 4, 4)  # scale z, y, x\n",
    "\n",
    "landmarkdf[f'x_{lm_name}'] = (landmarkdf['x_em_clemui'] / lm_scale_zyx[2]).round().astype(int)\n",
    "landmarkdf[f'y_{lm_name}'] = (landmarkdf['y_em_clemui'] / lm_scale_zyx[1]).round().astype(int)\n",
    "landmarkdf[f'z_{lm_name}'] = (landmarkdf['z_em_clemui'] / lm_scale_zyx[0]).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x_dp1_em_downsampled_stack    1448.957708\n",
       "y_dp1_em_downsampled_stack    1189.759887\n",
       "z_dp1_em_downsampled_stack    1583.895026\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from compute_affine3d_from_landmarks import invert_affine_matrix, transform_points\n",
    "\n",
    "# Convert {em_downsampled_transformed_name} to {em_downsampled_name} by applying affine3d\n",
    "em_downsampled_name = 'dp1_em_downsampled_stack'\n",
    "affine3d_mat = np.loadtxt(em_affine3d_file)\n",
    "inv_affine3d_mat = invert_affine_matrix(affine3d_mat)\n",
    "\n",
    "points = landmarkdf[[f'z_{em_downsampled_transformed_name}', f'y_{em_downsampled_transformed_name}', f'x_{em_downsampled_transformed_name}']].values\n",
    "# Apply affine3d_mat to points\n",
    "inv_transformed_points = transform_points(points, inv_affine3d_mat)\n",
    "inv_transformed_points\n",
    "\n",
    "landmarkdf[f'x_{em_downsampled_name}'] = inv_transformed_points[:, 2]\n",
    "landmarkdf[f'y_{em_downsampled_name}'] = inv_transformed_points[:, 1]\n",
    "landmarkdf[f'z_{em_downsampled_name}'] = inv_transformed_points[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert {em_downsampled_name} to neuroglancer\n",
    "em_downsample_scale_zyx = (176, 176, 200) # scale z, y, x\n",
    "neuroglancer_scale_ngxyz = (11, 11, 25) # Neuroglancer voxel size in nm in neuroglancer coordinates x, y, z\n",
    "\n",
    "# Note that the order of x, y, z is different in neuroglancer (due to permutations of axes caused in brainmaps export + imagej import+ imagej export, historical reasons, and non-careful handling of downsampled and meta data)\n",
    "# the unit is in pixel\n",
    "landmarkdf[f'x_neuroglancer_px'] = (landmarkdf[f'z_{em_downsampled_name}'] * em_downsample_scale_zyx[0] / neuroglancer_scale_ngxyz[0]).round().astype(int)\n",
    "landmarkdf[f'y_neuroglancer_px'] = (landmarkdf[f'y_{em_downsampled_name}'] * em_downsample_scale_zyx[1] / neuroglancer_scale_ngxyz[1]).round().astype(int)\n",
    "landmarkdf[f'z_neuroglancer_px'] = (landmarkdf[f'x_{em_downsampled_name}'] * em_downsample_scale_zyx[2] / neuroglancer_scale_ngxyz[2]).round().astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the full landmarkdf to a new csv file\n",
    "landmarkdf.to_csv(os.path.join(landmark_dir, f'{landmark_base_name}_lm_to_neuroglancer.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate json file\n",
    "# Template json file\n",
    "ng_json_dir = 'neuroglancer_json'\n",
    "template_json_file = os.path.join(ng_json_dir, 'from_Nila_221010_151223__dp_somata_.json')\n",
    "import json\n",
    "with open(template_json_file, 'r') as f:\n",
    "    template_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_json['layers'][1]['annotations']\n",
    "\n",
    "annotations = []\n",
    "for _, row in landmarkdf.iterrows():\n",
    "    # Get the coordinates\n",
    "    x = row[f'x_neuroglancer_px']\n",
    "    y = row[f'y_neuroglancer_px']\n",
    "    z = row[f'z_neuroglancer_px']\n",
    "    # Get the name\n",
    "    name = row['landmark_name']\n",
    "    # Get the radius\n",
    "    #radius = [250, 250, 110]  # in nm\n",
    "    radius = [100, 100, 44]  # in nm\n",
    "    # Create the annotation\n",
    "    annotation = {\n",
    "        'center': [x, y, z],\n",
    "        'radii': radius,\n",
    "        'type': 'ellipsoid',\n",
    "        'id': name,\n",
    "    }\n",
    "    annotations.append(annotation)\n",
    "# Replace the annotations to the template json\n",
    "template_json['layers'][1]['annotations'] = annotations\n",
    "\n",
    "# Save the json file\n",
    "import json\n",
    "json_file = os.path.join(ng_json_dir, f'{landmark_base_name}_lm_to_neuroglancer.json')\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(template_json, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
